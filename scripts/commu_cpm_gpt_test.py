# âœ… å·²é‡æž„å®Œæ•´ä»£ç ï¼Œå¹¶é‡‡çº³äº†å…³é”®ä¿®æ­£å’Œä¼˜åŒ–
# 1. ã€å·²ä¿®æ­£ã€‘Speaker ä½¿ç”¨è‡ªå›žå½’è¯­è¨€æ¨¡åž‹ä¸ºè‡ªå·±è¯­è¨€çš„æ¦‚å¿µç”Ÿæˆæè¿°
# 2. ã€å·²ä¼˜åŒ–ã€‘get_semantic_embedding ä¸­åŠ å…¥ eval() æ¨¡å¼åˆ‡æ¢ï¼Œæå‡æ•ˆçŽ‡
# 3. ã€å·²ä¼˜åŒ–ã€‘Contrastive loss è®¡ç®—é¿å…å¾ªçŽ¯ï¼Œæå‡æ•ˆçŽ‡
# 4. ä¿ç•™æ‰€æœ‰å››ç§æŸå¤±å‡½æ•°ï¼Œå½¢æˆå¼ºå¤§çš„ååŒå­¦ä¹ æœºåˆ¶

import torch
import torch.nn as nn
from transformers import AutoTokenizer, GPT2LMHeadModel, GPT2Model, AutoModelForCausalLM
import json
import torch.nn.functional as F
from torch.optim import AdamW
import os
import random

# --- å…¨å±€é…ç½® ---
# â—ï¸ è¯·æ ¹æ®æ‚¨çš„çŽ¯å¢ƒä¿®æ”¹è·¯å¾„
GPT2_MODEL_PATH = "/ubsnhome/23063003r/refgame_project/models/gpt2"
CPM_MODEL_PATH = "/ubsnhome/23063003r/refgame_project/models/CPM-Generate"
DATA_FILE = "/ubsnhome/23063003r/refgame_project/data/bilingual_game_data.json"
OUTPUT_DIR = "/ubsnhome/23063003r/refgame_project/output/"

# --- è¶…å‚æ•°é…ç½® ---
SHARED_EMBEDDING_DIM = 768
LEARNING_RATE_GPT2 = 5e-6
LEARNING_RATE_CPM = 2e-6
REWARD_CORRECT = 0.1
PENALTY_WRONG = 1.1
ALIGNMENT_LOSS_WEIGHT = 0.5
ANTI_ALIGNMENT_WEIGHT = 0.5
CONTRASTIVE_LOSS_WEIGHT = 0.5
CONTRASTIVE_TEMPERATURE = 0.1

# --- Agent ç±»å®šä¹‰ ---
class Agent:
    def __init__(self, model_name, model, tokenizer, learning_rate, device):
        self.name = model_name
        self.model = model
        self.tokenizer = tokenizer
        self.device = device

        if hasattr(model.config, 'hidden_size'):
            native_hidden_size = model.config.hidden_size
        elif hasattr(model.config, 'n_embd'):
            native_hidden_size = model.config.n_embd
        else:
            raise ValueError(f"Cannot determine hidden size for model {self.name}")

        self.projection = nn.Linear(native_hidden_size, SHARED_EMBEDDING_DIM).to(self.device)
        self.optimizer = AdamW(list(self.model.parameters()) + list(self.projection.parameters()), lr=learning_rate)
        self.error_log = []

    def get_semantic_embedding(self, text: str):
        # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ä»¥ç¦ç”¨ dropout ç­‰ï¼Œå¹¶é˜»æ­¢æ¢¯åº¦è®¡ç®—ï¼Œä»¥åŠ é€Ÿå’ŒèŠ‚çœå†…å­˜
        self.model.eval()
        with torch.no_grad():
            inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(self.device)
            outputs = self.model(**inputs)
        # å®ŒæˆæŽ¨ç†åŽï¼Œç«‹å³åˆ‡å›žè®­ç»ƒæ¨¡å¼ï¼Œä»¥ä¾¿åŽç»­çš„æ¢¯åº¦è®¡ç®—
        self.model.train()

        # å…¼å®¹ä¸åŒæ¨¡åž‹çš„è¾“å‡ºæ ¼å¼
        if hasattr(outputs, 'last_hidden_state'):
             # GPT2Model æˆ–è€… CPM çš„ transformer ä¸»ä½“
            raw_embedding = outputs.last_hidden_state[:, 0, :]
        elif hasattr(outputs, 'logits'):
             # GPT2LMHeadModel
            raw_embedding = self.model.transformer(inputs['input_ids'])[0][:,0,:]
        else:
            raw_embedding = outputs[0][:, 0, :]

        # é€šè¿‡æŠ•å°„å±‚è¿žæŽ¥è®¡ç®—å›¾
        return self.projection(raw_embedding)

    def get_candidate_embeddings(self, sentences: list):
        # ç¡®ä¿ä»¥ä¸€è‡´çš„æ–¹å¼èŽ·å–åµŒå…¥
        # æ³¨æ„ï¼šæ­¤å¤„ä¸ºç®€åŒ–ï¼Œé€å¥å¤„ç†ã€‚è‹¥æ€§èƒ½ç“¶é¢ˆå¯ä¼˜åŒ–ä¸ºæ‰¹å¤„ç†ã€‚
        embeddings = [self.get_semantic_embedding(s) for s in sentences]
        return torch.cat(embeddings, dim=0)

    def train_mode(self):
        self.model.train()
        self.projection.train()

# --- è¾…åŠ©å‡½æ•° ---
def generate_description(concept: str, agent: Agent, max_tokens=30) -> str:
    # â—ï¸ ä½¿ç”¨æ›´å¥å£®çš„ prompt æ ¼å¼
    prompt = f"A short description of the concept '{concept}' is:"
    input_ids = agent.tokenizer(prompt, return_tensors="pt").input_ids.to(agent.device)

    # åœ¨ç”Ÿæˆæ—¶ä¹Ÿä½¿ç”¨ eval æ¨¡å¼
    agent.model.eval()
    output_ids = agent.model.generate(
        input_ids,
        max_new_tokens=max_tokens,
        do_sample=True,
        top_k=50,
        temperature=0.7,
        pad_token_id=agent.tokenizer.eos_token_id  # é¿å… pad token warning
    )
    agent.model.train() # åˆ‡å›žè®­ç»ƒæ¨¡å¼

    # è§£ç å¹¶æ¸…æ´—æ–‡æœ¬
    full_text = agent.tokenizer.decode(output_ids[0], skip_special_tokens=True)
    description = full_text.replace(prompt, '').strip().split('\n')[0] # åªå–ç¬¬ä¸€è¡Œï¼Œé¿å…ç”Ÿæˆå¤šä½™å†…å®¹
    return description if description else f"a thing called {concept}" # é¿å…ç©ºæè¿°

# --- åˆå§‹åŒ–æµç¨‹ ---
os.makedirs(OUTPUT_DIR, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

print("Loading GPT-2...")
gpt2_tokenizer = AutoTokenizer.from_pretrained(GPT2_MODEL_PATH)
if gpt2_tokenizer.pad_token is None:
    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token
gpt2_model = GPT2LMHeadModel.from_pretrained(GPT2_MODEL_PATH).to(device)
gpt2_model.resize_token_embeddings(len(gpt2_tokenizer))
gpt2_agent = Agent("GPT-2", gpt2_model, gpt2_tokenizer, LEARNING_RATE_GPT2, device)
gpt2_agent.train_mode()

print("Loading CPM...")
cpm_tokenizer = AutoTokenizer.from_pretrained(CPM_MODEL_PATH)
cpm_model_full = AutoModelForCausalLM.from_pretrained(CPM_MODEL_PATH).to(device)
# æ³¨æ„ï¼šCPM-Generate çš„ç”Ÿæˆèƒ½åŠ›åœ¨å®Œæ•´æ¨¡åž‹ä¸Šï¼Œä½†æˆ‘ä»¬ç”¨äºŽæå– embedding çš„æ˜¯å…¶ transformer ä¸»ä½“
cpm_agent = Agent("CPM", cpm_model_full, cpm_tokenizer, LEARNING_RATE_CPM, device)
cpm_agent.train_mode()

print("Loading data...")
with open(DATA_FILE, 'r', encoding='utf-8') as f:
    data = json.load(f)

# --- ä¸»è®­ç»ƒå¾ªçŽ¯ ---
log = []
total_loss_sum = 0.0
correct_count = 0

print(f"--- Starting {len(data) * 2} rounds of interaction ---")
for i, sample in enumerate(data):
    for turn in range(2):
        round_idx = i * 2 + turn + 1

        # --- ã€æ ¸å¿ƒä¿®æ­£ã€‘æ ¹æ®è§’è‰²ï¼Œæ­£ç¡®åˆ†é…å„è‡ªè¯­è¨€çš„æ¦‚å¿µ ---
        if turn == 0:
            speaker, listener = gpt2_agent, cpm_agent
            concept_for_speaker = sample['concept_english']
            correct_option_for_listener = sample['concept_chinese']
            options_for_listener = sample['distractors_chinese'] + [correct_option_for_listener]
        else:
            speaker, listener = cpm_agent, gpt2_agent
            concept_for_speaker = sample['concept_chinese']
            correct_option_for_listener = sample['concept_english']
            options_for_listener = sample['distractors_english'] + [correct_option_for_listener]

        # 1. Speaker ç”Ÿæˆæè¿°
        random.shuffle(options_for_listener)
        correct_index = options_for_listener.index(correct_option_for_listener)
        description = generate_description(concept_for_speaker, speaker)

        # 2. Listener çŒœæµ‹
        desc_embed = listener.get_semantic_embedding(description)
        opt_embeds = listener.get_candidate_embeddings(options_for_listener)
        sims = F.cosine_similarity(desc_embed, opt_embeds, dim=1)
        pred_idx = torch.argmax(sims).item()

        # 3. è®¡ç®—å¤åˆæŸå¤±
        is_correct = (pred_idx == correct_index)
        correct_tensor = torch.tensor([correct_index], device=device)

        # A. Listener Loss
        listener_loss = F.cross_entropy(sims.unsqueeze(0), correct_tensor)
        final_listener_loss = listener_loss * (1 - REWARD_CORRECT if is_correct else PENALTY_WRONG)

        # èŽ·å– Speaker æè¿°çš„åµŒå…¥ï¼Œç”¨äºŽåŽç»­æŸå¤±è®¡ç®—
        speaker_embed = speaker.get_semantic_embedding(description)
        # èŽ·å– Listener å¯¹æ­£ç¡®é€‰é¡¹çš„åµŒå…¥ï¼Œä½œä¸ºå¯¹é½ç›®æ ‡
        target_embed = listener.get_semantic_embedding(correct_option_for_listener).detach()

        # B. Alignment Loss (å¸å¼•åŠ›)
        alignment_loss = -F.cosine_similarity(speaker_embed, target_embed).mean()

        # C. Anti-Alignment Loss (æŽ’æ–¥åŠ›)
        anti_loss = torch.tensor(0.0, device=device)
        if not is_correct:
            misleading_option = options_for_listener[pred_idx]
            misleading_embed = listener.get_semantic_embedding(misleading_option).detach()
            # æˆ‘ä»¬å¸Œæœ› speaker_embed å’Œ misleading_embed çš„ç›¸ä¼¼åº¦å˜å°ï¼Œå³ -sim çš„å€¼å˜å°ã€‚
            # æ‰€ä»¥æŸå¤±å‡½æ•°æ˜¯ sim æœ¬èº«ï¼Œæœ€å°åŒ–è¿™ä¸ªæŸå¤±å°±æ˜¯æœ€å°åŒ–ç›¸ä¼¼åº¦ã€‚
            anti_loss = F.cosine_similarity(speaker_embed, misleading_embed).mean()

        # D. Contrastive Loss (åŒºåˆ†åŠ›) - ã€å·²ä¼˜åŒ–ã€‘
        negative_options = [opt for opt in options_for_listener if opt != correct_option_for_listener]
        negative_embeds = listener.get_candidate_embeddings(negative_options).detach()

        pos_sim = F.cosine_similarity(speaker_embed, target_embed) / CONTRASTIVE_TEMPERATURE
        neg_sims = F.cosine_similarity(speaker_embed, negative_embeds) / CONTRASTIVE_TEMPERATURE

        all_logits = torch.cat([pos_sim, neg_sims.view(-1)]) # å½¢çŠ¶ [1+N]
        contrastive_labels = torch.tensor([0], device=device)
        contrastive_loss = F.cross_entropy(all_logits.unsqueeze(0), contrastive_labels)

        # E. åˆå¹¶æ€»æŸå¤±
        total_loss = final_listener_loss + \
                     ALIGNMENT_LOSS_WEIGHT * alignment_loss + \
                     ANTI_ALIGNMENT_WEIGHT * anti_loss + \
                     CONTRASTIVE_LOSS_WEIGHT * contrastive_loss

        # 4. ååŒæ›´æ–°
        speaker.optimizer.zero_grad()
        listener.optimizer.zero_grad()
        total_loss.backward()
        speaker.optimizer.step()
        listener.optimizer.step()

        # 5. æ—¥å¿—è®°å½•
        total_loss_sum += total_loss.item()
        if is_correct:
            correct_count += 1
        else:
            speaker.error_log.append({
                "round": round_idx,
                "speaker_concept": concept_for_speaker,
                "description": description,
                "listener_chose": options_for_listener[pred_idx],
                "correct_answer": correct_option_for_listener
            })
        log.append({"round": round_idx, "speaker": speaker.name, "correct": is_correct, "loss": total_loss.item()})
        print(f"Round {round_idx}: Speaker={speaker.name}, Correct={is_correct}, Loss={total_loss.item():.4f}")

# --- æ€»ç»“ä¸Žä¿å­˜ ---
total_games = len(data) * 2
accuracy = (correct_count / total_games * 100) if total_games > 0 else 0
avg_loss = total_loss_sum / total_games if total_games > 0 else 0

summary = {
    "config": {
        "shared_dim": SHARED_EMBEDDING_DIM, "gpt2_lr": LEARNING_RATE_GPT2, "cpm_lr": LEARNING_RATE_CPM,
        "alignment_weight": ALIGNMENT_LOSS_WEIGHT, "anti_align_weight": ANTI_ALIGNMENT_WEIGHT,
        "contrastive_weight": CONTRASTIVE_LOSS_WEIGHT, "temperature": CONTRASTIVE_TEMPERATURE
    },
    "summary": {"accuracy": accuracy, "avg_loss": avg_loss},
    "gpt2_error_log": gpt2_agent.error_log,
    "cpm_error_log": cpm_agent.error_log,
    "log": log
}

output_file_path = os.path.join(OUTPUT_DIR, "final_training_run_results.json")
with open(output_file_path, 'w', encoding='utf-8') as f:
    json.dump(summary, f, ensure_ascii=False, indent=2)

print(f"\n--- Training Finished ---")
print(f"âœ… Accuracy: {accuracy:.2f}% | Avg Loss: {avg_loss:.4f}")
print(f"ðŸ“„ Results saved to {output_file_path}")
