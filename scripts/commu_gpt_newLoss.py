import torch
from transformers import AutoTokenizer, GPT2Model
import json
import torch.nn.functional as F
from torch.optim import AdamW
from torch.utils.data import Dataset, DataLoader # å¼•å…¥DataLoader
import os
import random # å¼•å…¥randomç”¨äºshuffleæ•°æ®é›†

# --- 1. é…ç½®ç®¡ç† ---
class Config:
    MODEL_PATH = "/puhome/23063003r/refgame_project/models/gpt2"
    DATA_FILE = "/puhome/23063003r/refgame_project/data/generated_game_data.json"
    OUTPUT_DIR = "/puhome/23063003r/refgame_project/output/"
    D_HIDDEN = 768  # GPT-2çš„éšè—å±‚ç»´åº¦

    # Loss å¥–åŠ±/æƒ©ç½šç³»æ•°
    REWARD_CORRECT = 0.1
    PENALTY_WRONG = 1.0

    LEARNING_RATE = 1e-5
    BATCH_SIZE = 1 # ä¸ºäº†ç®€åŒ–ï¼Œç›®å‰ä»æŒ‰å•æ ·æœ¬å¤„ç†ï¼Œæœªæ¥å¯æ”¹ä¸ºæ›´å¤§
    # æ³¨æ„ï¼šå¦‚æœBATCH_SIZE > 1ï¼Œåˆ™DataLoaderçš„collate_fnéœ€è¦å¤„ç†padding

# --- 2. Listener Loss å‡½æ•° ---
def listener_mse_reciprocal_loss(
    semantic_vector_from_agent_A: torch.Tensor,
    semantic_vectors_candidates_B: torch.Tensor,
    correct_candidate_index: torch.Tensor,
    epsilon: float = 1e-8 # ç”¨äºæ•°å€¼ç¨³å®šçš„å°å¸¸æ•°
) -> torch.Tensor:
    """
    è®¡ç®— Listener Lossï¼Œé‡‡ç”¨è®ºæ–‡ä¸­ (EMERGENT TRANSLATION IN MULTI-AGENT COMMUNICATION)
    æè¿°çš„ MSE å€’æ•°å¯¹æ•°å½¢å¼ã€‚
    Args:
        semantic_vector_from_agent_A (torch.Tensor): Agent Aï¼ˆä¸­æ–‡ä¹±ç ï¼‰çš„è¯­ä¹‰å‘é‡ã€‚
                                                     æœŸæœ›å½¢çŠ¶: (batch_size, D_HIDDEN)
        semantic_vectors_candidates_B (torch.Tensor): Agent B å€™é€‰è‹±æ–‡å¥å­çš„è¯­ä¹‰å‘é‡é›†åˆã€‚
                                                      æœŸæœ›å½¢çŠ¶: (batch_size, num_candidates, D_HIDDEN)
        correct_candidate_index (torch.Tensor): æ­£ç¡®å€™é€‰å¥å­çš„ç´¢å¼•ã€‚
                                                æœŸæœ›å½¢çŠ¶: (batch_size,)
        epsilon (float): ç”¨äºæ•°å€¼ç¨³å®šçš„å°å¸¸æ•°ï¼Œé˜²æ­¢é™¤ä»¥é›¶ã€‚
    Returns:
        torch.Tensor: è®¡ç®—å‡ºçš„æŸå¤±å€¼ã€‚
    """
    print(f"DEBUG: semantic_vector_from_agent_A shape: {semantic_vector_from_agent_A.shape}, dtype: {semantic_vector_from_agent_A.dtype}")
    print(f"DEBUG: semantic_vectors_candidates_B shape: {semantic_vectors_candidates_B.shape}, dtype: {semantic_vectors_candidates_B.dtype}")
    print(f"DEBUG: correct_candidate_index shape: {correct_candidate_index.shape}, dtype: {correct_candidate_index.dtype}")

    # ç¡®ä¿ Agent A å‘é‡ç»´åº¦å¯ä»¥å¹¿æ’­åˆ°å€™é€‰å‘é‡
    # expanded_vector_A å½¢çŠ¶å˜ä¸º (batch_size, 1, D_HIDDEN)
    expanded_vector_A = semantic_vector_from_agent_A.unsqueeze(1)
    print(f"DEBUG: expanded_vector_A shape: {expanded_vector_A.shape}")

    # è®¡ç®— (E_EN^B(m_hat) - E_IMG^B(i_k))^2ï¼Œå³å‡æ–¹å·®çš„å¹³æ–¹éƒ¨åˆ†
    # ç»“æœå½¢çŠ¶: (batch_size, num_candidates, D_HIDDEN)
    squared_diff = (expanded_vector_A - semantic_vectors_candidates_B).pow(2)
    print(f"DEBUG: squared_diff shape: {squared_diff.shape}")

    # å¯¹ç‰¹å¾ç»´åº¦æ±‚å’Œï¼Œå¾—åˆ°æ¯ä¸ªå€™é€‰çš„ MSE è·ç¦»
    # ç»“æœå½¢çŠ¶: (batch_size, num_candidates)
    mse_distances = squared_diff.sum(dim=-1)
    print(f"DEBUG: mse_distances shape: {mse_distances.shape}")

    # è®ºæ–‡ä¸­çš„ logits æ˜¯ MSE çš„å€’æ•°ï¼Œæ·»åŠ  epsilon é¿å…é™¤é›¶
    logits = 1 / (mse_distances + epsilon)
    print(f"DEBUG: logits shape: {logits.shape}")

    # æŸå¤±å‡½æ•°æ˜¯ -log(softmax(logits))ï¼ŒF.cross_entropy å†…éƒ¨åŒ…å«äº† log_softmax
    # F.cross_entropy æœŸæœ› logits (N, C) å’Œ targets (N)
    # N æ˜¯ batch_size, C æ˜¯ num_candidates
    loss = F.cross_entropy(logits, correct_candidate_index)
    print(f"DEBUG: Final loss calculated.")

    return loss

# --- 3. Agent B (Listener) æ¨¡å‹ç±» ---
class AgentBListener(torch.nn.Module):
    def __init__(self, model_path, all_chinese_chars, hidden_dim):
        super().__init__()
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        # --- æ·»åŠ è¿™ä¸€è¡Œæ¥è®¾ç½® pad_token ---
        if self.tokenizer.pad_token is None: # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰pad_tokenï¼Œé¿å…é‡å¤è®¾ç½®
            self.tokenizer.pad_token = self.tokenizer.eos_token
        # --- ç»“æŸæ·»åŠ  ---
        self.model = GPT2Model.from_pretrained(model_path)

        # æ‰©å±• tokenizer å¹¶è°ƒæ•´ embedding å±‚
        self.tokenizer.add_special_tokens({'additional_special_tokens': list(all_chinese_chars)})
        self.model.resize_token_embeddings(len(self.tokenizer))

        # éªŒè¯ç»´åº¦
        assert hidden_dim == self.model.config.hidden_size, \
            "D_HIDDEN must match GPT-2's hidden_size for direct use as semantic vector."

        print(f"âœ… AgentB: GPT-2 tokenizer å·²æ‰©å±•ï¼Œæ–°çš„è¯æ±‡è¡¨å¤§å°: {len(self.tokenizer)}")
        print(f"âœ… AgentB: GPT-2 æ¨¡å‹ Embedding å±‚å·²è°ƒæ•´ã€‚")

    def forward(self, inputs_cn_symbolic_raw, inputs_en_candidates_raw, device):
        print(f"DEBUG_FORWARD_STEP2: inputs_cn_symbolic_raw (from DataLoader, before [0]): {inputs_cn_symbolic_raw}")
        print(f"DEBUG_FORWARD_STEP2: inputs_en_candidates_raw (from DataLoader, before [0]): {inputs_en_candidates_raw}")

        # 1. å¤„ç†ä¸­æ–‡ä¹±ç è¾“å…¥
        # inputs_cn_symbolic_raw æ˜¯ ['ä¸€ä¸ªè‹¹æœæ‰åˆ°äº†åœ°ä¸Šã€‚'] (list of 1 string)
        # ç¡®ä¿è¿™é‡Œåªå–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œå› ä¸ºå®ƒä»ç„¶æ˜¯ DataLoader åŒ…è£…è¿‡çš„
        cpm_sentence_for_tokenizer = inputs_cn_symbolic_raw[0]
        inputs_cn_symbolic = self.tokenizer(cpm_sentence_for_tokenizer, return_tensors="pt", padding=True, truncation=True).to(device)
        outputs_cn_symbolic = self.model(**inputs_cn_symbolic)
        semantic_vector_B_from_A = outputs_cn_symbolic.last_hidden_state[:, 0, :]


        # 2. Agent B å¤„ç†è‹±æ–‡å€™é€‰å¥å­ (å†æ¬¡ä»”ç»†æ£€æŸ¥è¿™é‡Œ)
        # inputs_en_candidates_raw æ˜¯ [['å€™é€‰1', 'å€™é€‰2', 'å€™é€‰3']] æˆ–è€… [('å€™é€‰1',)] è¿™æ ·çš„æ ¼å¼
        # æˆ‘ä»¬éœ€è¦æå–å‡º ['å€™é€‰1', 'å€™é€‰2', 'å€™é€‰3']
        english_sentences_list = inputs_en_candidates_raw[0]
        print(f"DEBUG_FORWARD_STEP2: english_sentences_list (after [0] from inputs_en_candidates_raw): {english_sentences_list}, type: {type(english_sentences_list)}")
        # æœŸæœ›è¿™é‡Œæ˜¯ä¸€ä¸ªåŒ…å«3ä¸ªå­—ç¬¦ä¸²çš„åˆ—è¡¨ï¼Œå¦‚ ['An apple...', 'The cat...', 'A red...']

        # æ£€æŸ¥æ˜¯å¦æ˜¯å…ƒç»„
        if isinstance(english_sentences_list, tuple):
            print(f"è­¦å‘Š: english_sentences_list æ˜¯ä¸€ä¸ªå…ƒç»„ï¼å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨ã€‚")
            english_sentences_list = list(english_sentences_list)

        # æ£€æŸ¥åˆ—è¡¨é•¿åº¦
        if not isinstance(english_sentences_list, list) or len(english_sentences_list) < 3: # å‡è®¾ num_candidates æ˜¯3
            print(f"ä¸¥é‡é”™è¯¯: english_sentences_list ä¸æ˜¯åˆ—è¡¨æˆ–é•¿åº¦ä¸è¶³3ï¼å®é™…: {english_sentences_list}")
            # è¿™é‡Œå¯ä»¥ç›´æ¥ raise TypeError æˆ– AssertionError æ¥æå‰æŠ¥é”™
            raise ValueError(f"å€™é€‰è‹±æ–‡å¥å­æ•°é‡ä¸è¶³æˆ–æ ¼å¼é”™è¯¯: {english_sentences_list}")


        inputs_en_candidates_tokenized = self.tokenizer(
            english_sentences_list, # ä¼ å…¥å­—ç¬¦ä¸²åˆ—è¡¨
            return_tensors="pt",
            padding=True,
            truncation=True
        ).to(device)

        print(f"DEBUG_TOKENIZER_AFTER_FIX_STEP2: inputs_en_candidates_tokenized input_ids shape: {inputs_en_candidates_tokenized['input_ids'].shape}")
        # æœŸæœ›å½¢çŠ¶: (num_candidates, max_seq_len), ä¾‹å¦‚ (3, max_len)

        outputs_en_candidates = self.model(**inputs_en_candidates_tokenized)

        semantic_vectors_B_candidates = outputs_en_candidates.last_hidden_state[:, 0, :]

        semantic_vectors_B_candidates = semantic_vectors_B_candidates.unsqueeze(0) # å˜ä¸º (1, num_candidates, D_HIDDEN)

        return semantic_vector_B_from_A, semantic_vectors_B_candidates, embedding_before
        
    def get_embedding_after(self):
        return self.model.wte.weight.detach()

# --- 4. æ¸¸æˆæ•°æ®åŠ è½½å™¨ ---
class GameDataset(Dataset):
    def __init__(self, data_file):
        with open(data_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

# --- 5. æ¸¸æˆè®­ç»ƒå¾ªç¯ ---
class GameTrainer:
    def __init__(self, config: Config, model: AgentBListener, optimizer: AdamW, device: torch.device):
        self.config = config
        self.model = model
        self.optimizer = optimizer
        self.device = device
        self.per_round_metrics = []
        self.total_loss_sum = 0.0
        self.correct_predictions_count = 0

    def train_one_round(self, game_round: dict, round_idx: int, total_rounds: int): # game_round ç°åœ¨æ˜¯åŸå§‹å­—å…¸
        self.optimizer.zero_grad()

        cpm_spoken_chinese_sentence = game_round['target_sentence_chinese_raw']

        # 1. Agent B (GPT-2) å¤„ç†ä¸­æ–‡ä¹±ç è¾“å…¥åŠè‹±æ–‡å€™é€‰å¥å­
        # inputs_cn_symbolic_raw åº”è¯¥æ˜¯ ['å¥å­'] (åˆ—è¡¨åŒ…å«ä¸€ä¸ªå­—ç¬¦ä¸²)
        # inputs_en_candidates_raw åº”è¯¥æ˜¯ [['å€™é€‰1', 'å€™é€‰2', 'å€™é€‰3']] (åˆ—è¡¨åŒ…å«ä¸€ä¸ªåˆ—è¡¨)

        # å°†å­—ç¬¦ä¸²åŒ…è£…æˆåˆ—è¡¨ï¼Œå› ä¸º forward æœŸæœ› batch_size ä¸ªå…ƒç´ 
        semantic_vector_B_from_A, semantic_vectors_B_candidates, embedding_before = \
            self.model(
                [cpm_spoken_chinese_sentence], # ä¼ å…¥ list of string
                [game_round['candidate_english_sentences_raw']], # ä¼ å…¥ list of list of string
                self.device
            )

        # 3. Agent B çŒœæµ‹ (è®¡ç®—ç›¸ä¼¼åº¦å¹¶é¢„æµ‹)
        # similarities: (1, num_candidates) -> squeeze(0) to (num_candidates,)
        similarities = F.cosine_similarity(
            semantic_vector_B_from_A,
            semantic_vectors_B_candidates.squeeze(0), # squeeze to match (num_candidates, D_HIDDEN) for comparison
            dim=1 # Compare along the D_HIDDEN dimension
        )
        predicted_index = torch.argmax(similarities).item()

        print(f"ğŸ¤” ç›¸ä¼¼åº¦å¾—åˆ† (è¶Šé«˜è¶Šç›¸ä¼¼): {similarities.tolist()}")
        print(f"ğŸ”® Agent B çŒœæµ‹çš„ç´¢å¼•: {predicted_index}")

        # 4. åé¦ˆä¸æƒé‡æ›´æ–° (Agent B å­¦ä¹ )
        correct_index_tensor = torch.tensor([game_round['correct_candidate_index']], device=self.device)

        # ä½¿ç”¨ Listener Loss å‡½æ•°
        base_loss = listener_mse_reciprocal_loss(
            semantic_vector_B_from_A,
            semantic_vectors_B_candidates, # æœŸæœ› (batch_size, num_candidates, D_HIDDEN)
            correct_index_tensor
        )

        is_correct = (predicted_index == game_round['correct_candidate_index'])
        if is_correct:
            loss = base_loss * (1 - self.config.REWARD_CORRECT)
            outcome_message = f"ğŸ‰ Agent B çŒœå¯¹å•¦ï¼æŸå¤±è°ƒæ•´ç³»æ•°: {(1 - self.config.REWARD_CORRECT):.2f}"
        else:
            loss = base_loss * self.config.PENALTY_WRONG
            outcome_message = f"ğŸ’” Agent B çŒœé”™äº†ï¼æŸå¤±è°ƒæ•´ç³»æ•°: {self.config.PENALTY_WRONG:.2f}"

        print(outcome_message)

        loss.backward()
        self.optimizer.step()

        # 5. æ¯”è¾ƒ Embedding å˜åŒ–
        embedding_after = self.model.get_embedding_after()
        diff = torch.norm(embedding_after - embedding_before).item()

        self.total_loss_sum += loss.item()
        if is_correct:
            self.correct_predictions_count += 1

        print(f"ğŸ“‰ æœ¬è½®æ¸¸æˆæœ€ç»ˆæŸå¤±: {loss.item():.4f}")
        print(f"ğŸ” Embedding (word token embeddings) æ”¹å˜é‡: {diff:.6f}")
        print(f"âœ¨ Agent B æœ€ç»ˆçŒœæµ‹ç»“æœ: {is_correct}")

        # è®°å½•æœ¬è½®æ•°æ®
        round_data = {
            "round_idx": round_idx,
            "chinese_sentence": game_round['target_sentence_chinese_raw'],
            "correct_english_sentence": game_round['correct_english_sentence_raw'],
            "candidate_english_sentences": game_round['candidate_english_sentences_raw'],
            "correct_candidate_idx": game_round['correct_candidate_index'],
            "predicted_index": predicted_index,
            "similarities": similarities.tolist(),
            "is_correct_prediction": is_correct,
            "base_loss": base_loss.item(),
            "final_loss": loss.item(),
            "embedding_diff_norm": diff
        }
        self.per_round_metrics.append(round_data)

    def train(self):
        game_dataset = GameDataset(self.config.DATA_FILE)
        data_loader = DataLoader(game_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False) # shuffle=True for real training

        self.model.model.train() # Set model to training mode
        total_rounds = len(data_loader)
        print(f"\n--- å‡†å¤‡è¿›è¡Œ {total_rounds} è½®æ¸¸æˆ ---")

        for i, raw_game_round_from_dataloader in enumerate(data_loader): # DataLoader è¿”å›åŸå§‹å­—å…¸çš„æ‰¹æ¬¡
            # raw_game_round_from_dataloader['target_sentence_chinese_raw'] ä¼šæ˜¯ä¸€ä¸ª (batch_size,) çš„å…ƒç»„æˆ–åˆ—è¡¨
            # raw_game_round_from_dataloader['candidate_english_sentences_raw'] ä¼šæ˜¯ä¸€ä¸ª (batch_size, num_candidates) çš„å…ƒç»„çš„å…ƒç»„æˆ–åˆ—è¡¨çš„åˆ—è¡¨

            # ç”±äºç›®å‰ batch_size=1, DataLoader ä¼šå°†æ¯ä¸ªå­—æ®µçš„å€¼åŒ…è£…æˆä¸€ä¸ªå…ƒç»„æˆ–åŒ…å«ä¸€ä¸ªå…ƒç´ çš„åˆ—è¡¨
            # ä¾‹å¦‚ï¼Œ{'target_sentence_chinese_raw': ('ä½ çœ‹èµ·æ¥åƒä¸€ä¸ªèªæ˜äººã€‚',), ...}
            # æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä»è¿™ä¸ªåŒ…è£…ä¸­å–å‡ºåŸå§‹å€¼
            single_game_round = {
                'target_sentence_chinese_raw': raw_game_round_from_dataloader['target_sentence_chinese_raw'][0],
                'correct_english_sentence_raw': raw_game_round_from_dataloader['correct_english_sentence_raw'][0],
                'candidate_english_sentences_raw': raw_game_round_from_dataloader['candidate_english_sentences_raw'][0], # è¿™æ˜¯æ­£ç¡®çš„ï¼Œå¾—åˆ° ['S1', 'S2', 'S3']
                'correct_candidate_index': raw_game_round_from_dataloader['correct_candidate_index'][0].item() # è½¬æ¢ä¸ºPython int
            }

            print(f"\n--- æ¸¸æˆå›åˆ {i + 1}/{total_rounds} ---")
            print(f"ğŸ¯ ç›®æ ‡ä¸­æ–‡å¥å­ (CPM 'è¯´'): {single_game_round['target_sentence_chinese_raw']}")
            print(f"ğŸ“š å€™é€‰è‹±æ–‡å¥å­ (Agent B é€‰æ‹©): {single_game_round['candidate_english_sentences_raw']}")
            print(f"âœ… æ­£ç¡®ç´¢å¼•: {single_game_round['correct_candidate_index']}")

            self.train_one_round(single_game_round, i + 1, total_rounds) # ä¼ å…¥è§£åŒ…åçš„å­—å…¸


        # --- è®­ç»ƒç»“æŸï¼Œæ±‡æ€»ç»“æœå¹¶ä¿å­˜ ---
        print("\n--- è®­ç»ƒæ€»ç»“ ---")
        final_accuracy_percentage = (self.correct_predictions_count / total_rounds * 100) if total_rounds > 0 else 0
        print(f"æ€»è½®æ•°: {total_rounds}")
        print(f"å¹³å‡æŸå¤±: {self.total_loss_sum / total_rounds:.4f}")
        print(f"çŒœå¯¹è½®æ•°: {self.correct_predictions_count}")
        print(f"å‡†ç¡®ç‡: {final_accuracy_percentage:.2f}%")

        # --- ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶ ---
        summary_metrics = {
            "total_rounds": total_rounds,
            "final_average_loss": self.total_loss_sum / total_rounds,
            "final_correct_count": self.correct_predictions_count,
            "final_accuracy_percentage": final_accuracy_percentage
        }

        output_data = {
            "summary_metrics": summary_metrics,
            "per_round_metrics": self.per_round_metrics
        }

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)

        output_file_path = os.path.join(self.config.OUTPUT_DIR, "training_results_newLoss.json")
        with open(output_file_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ‰ è®­ç»ƒç»“æœå·²ä¿å­˜åˆ°: {output_file_path}")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # 1. æ”¶é›†æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ä»¥æ‰©å±•tokenizer
    all_chinese_chars_in_corpus = set()
    try:
        with open(Config.DATA_FILE, 'r', encoding='utf-8') as f:
            temp_game_data = json.load(f)
        for entry in temp_game_data:
            all_chinese_chars_in_corpus.update(list(entry['target_sentence_chinese_raw']))
    except Exception as e:
        print(f"âŒ é”™è¯¯åŠ è½½æ•°æ®ä»¥æ”¶é›†ä¸­æ–‡ç¬¦å·ï¼Œä½¿ç”¨é»˜è®¤é›†: {e}")
        all_chinese_chars_in_corpus = set("ä¸€ä¸ªè‹¹æœæ‰åˆ°äº†åœ°ä¸Šã€‚çŒ«è·³åˆ°äº†æ¡Œå­ä¸Šã€‚ä¸€è¾†çº¢è‰²çš„æ±½è½¦å¼€åœ¨è¡—ä¸Šã€‚ç‹—è¿½çƒã€‚å¤©ç©ºæ˜¯è“è‰²çš„ã€‚å¥¹åœ¨çœ‹ä¹¦ã€‚ç¡æ²™å‘ã€‚å­©å­ä»¬åœ¨å…¬å›­ç©ã€‚å¤ªé˜³ä»ä¸œæ–¹å‡èµ·ã€‚å–œæ¬¢å¬éŸ³ä¹ã€‚å’–å•¡å¾ˆçƒ«ã€‚æˆ‘é¥¿äº†æƒ³åƒä¸œè¥¿ã€‚")


    # 2. åˆå§‹åŒ– Agent B æ¨¡å‹
    agent_b_model = AgentBListener(Config.MODEL_PATH, all_chinese_chars_in_corpus, Config.D_HIDDEN)
    agent_b_model.to(device) # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡

    # 3. åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = AdamW(agent_b_model.parameters(), lr=Config.LEARNING_RATE)

    # 4. åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = GameTrainer(Config, agent_b_model, optimizer, device)

    # 5. å¼€å§‹è®­ç»ƒ
    trainer.train()
