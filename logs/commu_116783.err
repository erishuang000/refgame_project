The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Traceback (most recent call last):
  File "/hpc2/puhome/23063003r/refgame_project/scripts/commu_gpt_newLoss.py", line 346, in <module>
    trainer.train()
  File "/hpc2/puhome/23063003r/refgame_project/scripts/commu_gpt_newLoss.py", line 282, in train
    self.train_one_round(single_game_round, i + 1, total_rounds) # 传入解包后的字典
  File "/hpc2/puhome/23063003r/refgame_project/scripts/commu_gpt_newLoss.py", line 186, in train_one_round
    self.model(
  File "/puhome/23063003r/.conda/envs/refgame/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/puhome/23063003r/.conda/envs/refgame/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hpc2/puhome/23063003r/refgame_project/scripts/commu_gpt_newLoss.py", line 128, in forward
    raise ValueError(f"候选英文句子数量不足或格式错误: {english_sentences_list}")
ValueError: 候选英文句子数量不足或格式错误: ["Tom wasn't able to fix the radio."]
