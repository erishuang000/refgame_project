ğŸš€ ä½œä¸šå¼€å§‹äº: Wed Jun 25 06:56:35 UTC 2025
ğŸ“Œ èŠ‚ç‚¹: c03
ğŸ”§ ä½¿ç”¨ CPU æ ¸æ•°: 8
Using device: cpu
Loading data to collect Chinese vocabulary for GPT-2...
Found 20 unique Chinese words/characters to add to GPT-2 tokenizer.
Loading and configuring GPT-2...
GPT-2 tokenizer vocabulary extended. New size: 50277
GPT-2 model embedding layer resized.
Loading CPM...

--- Starting 4 rounds of interaction (Verbose Mode) ---


========================= æ¸¸æˆå›åˆ 1 =========================

â–¶ï¸  é˜¶æ®µ 1: è§’è‰²åˆ†é…ä¸ä»»åŠ¡è®¾ç½®
    ğŸ—£ï¸  Speaker: GPT-2
    ğŸ‘‚  Listener: CPM

â–¶ï¸  é˜¶æ®µ 2: Speaker ç”Ÿæˆæè¿°
    Speakeræ¥æ”¶åˆ°çš„æ¦‚å¿µ: 'airplane'
    Speakerç”Ÿæˆçš„æè¿°: '"An airplane is a mass of metal and a gas, with a lift produced by an engine. In the case of a gas, the'

â–¶ï¸  é˜¶æ®µ 3: Listener ç†è§£ä¸çŒœæµ‹
    Listeneræ¥æ”¶åˆ°çš„é€‰é¡¹: ['å­¦æ ¡', 'æ©˜å­', 'é£æœº', 'è€å¸ˆ']
    (æœ¬è½®æ­£ç¡®ç­”æ¡ˆæ˜¯ç´¢å¼• 2: 'é£æœº')
    è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦:
        - é€‰é¡¹ 'å­¦æ ¡': 0.8320
        - é€‰é¡¹ 'æ©˜å­': 0.8328
        - é€‰é¡¹ 'é£æœº': 0.8560
        - é€‰é¡¹ 'è€å¸ˆ': 0.8576
    Listenerçš„é€‰æ‹©: ç´¢å¼• 3 -> 'è€å¸ˆ'
    âŒ ç»“è®º: çŒœæµ‹é”™è¯¯ï¼

â–¶ï¸  é˜¶æ®µ 4: å¤åˆæŸå¤±è®¡ç®— (è¯¦ç»†åˆ†è§£)
    [A] Listener Loss:
        - åŸºç¡€äº¤å‰ç†µæŸå¤±: 1.3749
        - å¥–æƒ©ç³»æ•°: 1.10 (æƒ©ç½š)
        -  => æœ€ç»ˆ Listener Loss = 1.5124
    [B] Alignment Loss (å¸å¼•åŠ›):
        - ç›®æ ‡: æ‹‰è¿‘'"An airplane is a ma...'å’Œ'é£æœº'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Alignment Loss = -0.0085
    [C] Anti-Alignment Loss (æ’æ–¥åŠ›):
        - ç›®æ ‡: æ¨è¿œ'"An airplane is a ma...'å’Œè¢«é”™é€‰çš„'è€å¸ˆ'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Anti-Alignment Loss = 0.0103
    [D] Contrastive Loss (åŒºåˆ†åŠ›):
        - ç›®æ ‡: è®©'"An airplane is a ma...'ä¸'é£æœº'çš„ç›¸ä¼¼åº¦è¿œé«˜äºå…¶ä»–æ‰€æœ‰é€‰é¡¹
        -  => è®¡ç®—å‡ºçš„ Contrastive Loss = 1.3485
    [E] æ€»æŸå¤±è®¡ç®—:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5124 + (0.5 * -0.0085) + (0.5 * 0.0103) + (0.5 * 1.3485)
                   = 1.5124 + -0.0042 + 0.0051 + 0.6743
        ----------------------------------------
        ==> ğŸ’¸ æœ€ç»ˆæ€»æŸå¤± (Final Total Loss): 2.1876

â–¶ï¸  é˜¶æ®µ 5: æ¨¡å‹ååŒæ›´æ–°
    æ‰§è¡Œ total_loss.backward() è®¡ç®—ä¸¤ä¸ªAgentæ‰€æœ‰ç›¸å…³å‚æ•°çš„æ¢¯åº¦...
    æ‰§è¡Œ speaker.optimizer.step() æ›´æ–° GPT-2 çš„æƒé‡...
    æ‰§è¡Œ listener.optimizer.step() æ›´æ–° CPM çš„æƒé‡...
    âœ… æ›´æ–°å®Œæˆ!


========================= æ¸¸æˆå›åˆ 2 =========================

â–¶ï¸  é˜¶æ®µ 1: è§’è‰²åˆ†é…ä¸ä»»åŠ¡è®¾ç½®
    ğŸ—£ï¸  Speaker: CPM
    ğŸ‘‚  Listener: GPT-2

â–¶ï¸  é˜¶æ®µ 2: Speaker ç”Ÿæˆæè¿°
    Speakeræ¥æ”¶åˆ°çš„æ¦‚å¿µ: 'é£æœº'
    Speakerç”Ÿæˆçš„æè¿°: '''''''''''''''''

â–¶ï¸  é˜¶æ®µ 3: Listener ç†è§£ä¸çŒœæµ‹
    Listeneræ¥æ”¶åˆ°çš„é€‰é¡¹: ['teacher', 'orange', 'school', 'airplane']
    (æœ¬è½®æ­£ç¡®ç­”æ¡ˆæ˜¯ç´¢å¼• 3: 'airplane')
    è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦:
        - é€‰é¡¹ 'teacher': 0.3072
        - é€‰é¡¹ 'orange': 0.3442
        - é€‰é¡¹ 'school': 0.2895
        - é€‰é¡¹ 'airplane': 0.2528
    Listenerçš„é€‰æ‹©: ç´¢å¼• 1 -> 'orange'
    âŒ ç»“è®º: çŒœæµ‹é”™è¯¯ï¼

â–¶ï¸  é˜¶æ®µ 4: å¤åˆæŸå¤±è®¡ç®— (è¯¦ç»†åˆ†è§£)
    [A] Listener Loss:
        - åŸºç¡€äº¤å‰ç†µæŸå¤±: 1.4325
        - å¥–æƒ©ç³»æ•°: 1.10 (æƒ©ç½š)
        -  => æœ€ç»ˆ Listener Loss = 1.5757
    [B] Alignment Loss (å¸å¼•åŠ›):
        - ç›®æ ‡: æ‹‰è¿‘''''''''''''''''...'å’Œ'airplane'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Alignment Loss = -0.0252
    [C] Anti-Alignment Loss (æ’æ–¥åŠ›):
        - ç›®æ ‡: æ¨è¿œ''''''''''''''''...'å’Œè¢«é”™é€‰çš„'orange'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Anti-Alignment Loss = -0.0080
    [D] Contrastive Loss (åŒºåˆ†åŠ›):
        - ç›®æ ‡: è®©''''''''''''''''...'ä¸'airplane'çš„ç›¸ä¼¼åº¦è¿œé«˜äºå…¶ä»–æ‰€æœ‰é€‰é¡¹
        -  => è®¡ç®—å‡ºçš„ Contrastive Loss = 1.4079
    [E] æ€»æŸå¤±è®¡ç®—:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5757 + (0.5 * -0.0252) + (0.5 * -0.0080) + (0.5 * 1.4079)
                   = 1.5757 + -0.0126 + -0.0040 + 0.7039
        ----------------------------------------
        ==> ğŸ’¸ æœ€ç»ˆæ€»æŸå¤± (Final Total Loss): 2.2630

â–¶ï¸  é˜¶æ®µ 5: æ¨¡å‹ååŒæ›´æ–°
    æ‰§è¡Œ total_loss.backward() è®¡ç®—ä¸¤ä¸ªAgentæ‰€æœ‰ç›¸å…³å‚æ•°çš„æ¢¯åº¦...
    æ‰§è¡Œ speaker.optimizer.step() æ›´æ–° CPM çš„æƒé‡...
    æ‰§è¡Œ listener.optimizer.step() æ›´æ–° GPT-2 çš„æƒé‡...
    âœ… æ›´æ–°å®Œæˆ!


========================= æ¸¸æˆå›åˆ 3 =========================

â–¶ï¸  é˜¶æ®µ 1: è§’è‰²åˆ†é…ä¸ä»»åŠ¡è®¾ç½®
    ğŸ—£ï¸  Speaker: GPT-2
    ğŸ‘‚  Listener: CPM

â–¶ï¸  é˜¶æ®µ 2: Speaker ç”Ÿæˆæè¿°
    Speakeræ¥æ”¶åˆ°çš„æ¦‚å¿µ: 'cat'
    Speakerç”Ÿæˆçš„æè¿°: 'a cat is a furry mammal with a short tail, which is not particularly useful for catching prey.'

â–¶ï¸  é˜¶æ®µ 3: Listener ç†è§£ä¸çŒœæµ‹
    Listeneræ¥æ”¶åˆ°çš„é€‰é¡¹: ['ç‹—', 'æ²™å‘', 'çŒ«', 'ä¹¦æœ¬']
    (æœ¬è½®æ­£ç¡®ç­”æ¡ˆæ˜¯ç´¢å¼• 2: 'çŒ«')
    è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦:
        - é€‰é¡¹ 'ç‹—': 0.7901
        - é€‰é¡¹ 'æ²™å‘': 0.8430
        - é€‰é¡¹ 'çŒ«': 0.7941
        - é€‰é¡¹ 'ä¹¦æœ¬': 0.7993
    Listenerçš„é€‰æ‹©: ç´¢å¼• 1 -> 'æ²™å‘'
    âŒ ç»“è®º: çŒœæµ‹é”™è¯¯ï¼

â–¶ï¸  é˜¶æ®µ 4: å¤åˆæŸå¤±è®¡ç®— (è¯¦ç»†åˆ†è§£)
    [A] Listener Loss:
        - åŸºç¡€äº¤å‰ç†µæŸå¤±: 1.3991
        - å¥–æƒ©ç³»æ•°: 1.10 (æƒ©ç½š)
        -  => æœ€ç»ˆ Listener Loss = 1.5390
    [B] Alignment Loss (å¸å¼•åŠ›):
        - ç›®æ ‡: æ‹‰è¿‘'a cat is a furry mam...'å’Œ'çŒ«'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Alignment Loss = -0.0357
    [C] Anti-Alignment Loss (æ’æ–¥åŠ›):
        - ç›®æ ‡: æ¨è¿œ'a cat is a furry mam...'å’Œè¢«é”™é€‰çš„'æ²™å‘'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Anti-Alignment Loss = -0.0132
    [D] Contrastive Loss (åŒºåˆ†åŠ›):
        - ç›®æ ‡: è®©'a cat is a furry mam...'ä¸'çŒ«'çš„ç›¸ä¼¼åº¦è¿œé«˜äºå…¶ä»–æ‰€æœ‰é€‰é¡¹
        -  => è®¡ç®—å‡ºçš„ Contrastive Loss = 1.5550
    [E] æ€»æŸå¤±è®¡ç®—:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5390 + (0.5 * -0.0357) + (0.5 * -0.0132) + (0.5 * 1.5550)
                   = 1.5390 + -0.0179 + -0.0066 + 0.7775
        ----------------------------------------
        ==> ğŸ’¸ æœ€ç»ˆæ€»æŸå¤± (Final Total Loss): 2.2920

â–¶ï¸  é˜¶æ®µ 5: æ¨¡å‹ååŒæ›´æ–°
    æ‰§è¡Œ total_loss.backward() è®¡ç®—ä¸¤ä¸ªAgentæ‰€æœ‰ç›¸å…³å‚æ•°çš„æ¢¯åº¦...
    æ‰§è¡Œ speaker.optimizer.step() æ›´æ–° GPT-2 çš„æƒé‡...
    æ‰§è¡Œ listener.optimizer.step() æ›´æ–° CPM çš„æƒé‡...
    âœ… æ›´æ–°å®Œæˆ!


========================= æ¸¸æˆå›åˆ 4 =========================

â–¶ï¸  é˜¶æ®µ 1: è§’è‰²åˆ†é…ä¸ä»»åŠ¡è®¾ç½®
    ğŸ—£ï¸  Speaker: CPM
    ğŸ‘‚  Listener: GPT-2

â–¶ï¸  é˜¶æ®µ 2: Speaker ç”Ÿæˆæè¿°
    Speakeræ¥æ”¶åˆ°çš„æ¦‚å¿µ: 'çŒ«'
    Speakerç”Ÿæˆçš„æè¿°: 'It's flannel work 'cats' 'cats'

â–¶ï¸  é˜¶æ®µ 3: Listener ç†è§£ä¸çŒœæµ‹
    Listeneræ¥æ”¶åˆ°çš„é€‰é¡¹: ['dog', 'book', 'sofa', 'cat']
    (æœ¬è½®æ­£ç¡®ç­”æ¡ˆæ˜¯ç´¢å¼• 3: 'cat')
    è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦:
        - é€‰é¡¹ 'dog': 0.5642
        - é€‰é¡¹ 'book': 0.5284
        - é€‰é¡¹ 'sofa': 0.5756
        - é€‰é¡¹ 'cat': 0.3887
    Listenerçš„é€‰æ‹©: ç´¢å¼• 2 -> 'sofa'
    âŒ ç»“è®º: çŒœæµ‹é”™è¯¯ï¼

â–¶ï¸  é˜¶æ®µ 4: å¤åˆæŸå¤±è®¡ç®— (è¯¦ç»†åˆ†è§£)
    [A] Listener Loss:
        - åŸºç¡€äº¤å‰ç†µæŸå¤±: 1.5145
        - å¥–æƒ©ç³»æ•°: 1.10 (æƒ©ç½š)
        -  => æœ€ç»ˆ Listener Loss = 1.6660
    [B] Alignment Loss (å¸å¼•åŠ›):
        - ç›®æ ‡: æ‹‰è¿‘'It's flannel work 'c...'å’Œ'cat'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Alignment Loss = -0.0641
    [C] Anti-Alignment Loss (æ’æ–¥åŠ›):
        - ç›®æ ‡: æ¨è¿œ'It's flannel work 'c...'å’Œè¢«é”™é€‰çš„'sofa'çš„è¯­ä¹‰è·ç¦»
        -  => è®¡ç®—å‡ºçš„ Anti-Alignment Loss = 0.0065
    [D] Contrastive Loss (åŒºåˆ†åŠ›):
        - ç›®æ ‡: è®©'It's flannel work 'c...'ä¸'cat'çš„ç›¸ä¼¼åº¦è¿œé«˜äºå…¶ä»–æ‰€æœ‰é€‰é¡¹
        -  => è®¡ç®—å‡ºçš„ Contrastive Loss = 1.3851
    [E] æ€»æŸå¤±è®¡ç®—:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.6660 + (0.5 * -0.0641) + (0.5 * 0.0065) + (0.5 * 1.3851)
                   = 1.6660 + -0.0321 + 0.0033 + 0.6925
        ----------------------------------------
        ==> ğŸ’¸ æœ€ç»ˆæ€»æŸå¤± (Final Total Loss): 2.3297

â–¶ï¸  é˜¶æ®µ 5: æ¨¡å‹ååŒæ›´æ–°
    æ‰§è¡Œ total_loss.backward() è®¡ç®—ä¸¤ä¸ªAgentæ‰€æœ‰ç›¸å…³å‚æ•°çš„æ¢¯åº¦...
    æ‰§è¡Œ speaker.optimizer.step() æ›´æ–° CPM çš„æƒé‡...
    æ‰§è¡Œ listener.optimizer.step() æ›´æ–° GPT-2 çš„æƒé‡...
    âœ… æ›´æ–°å®Œæˆ!


========================= è®­ç»ƒç»“æŸ =========================
âœ… å‡†ç¡®ç‡: 0.00% | å¹³å‡æŸå¤±: 2.2681
ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: /ubsnhome/23063003r/refgame_project/output/final_training_run_results_verbose.json
âœ… ä½œä¸šç»“æŸäº: Wed Jun 25 06:58:16 UTC 2025
