🚀 作业开始于: Wed Jun 25 06:09:56 UTC 2025
📌 节点: c03
🔧 使用 CPU 核数: 8
Using device: cpu
Loading GPT-2...
Loading CPM...
Loading data...

--- Starting 4 rounds of interaction (Verbose Mode) ---


========================= 游戏回合 1 =========================

▶️  阶段 1: 角色分配与任务设置
    🗣️  Speaker: GPT-2
    👂  Listener: CPM

▶️  阶段 2: Speaker 生成描述
    Speaker接收到的概念: 'airplane'
    Speaker生成的描述: 'an object of motion, with the ability to fly under its own power.'

▶️  阶段 3: Listener 理解与猜测
    Listener接收到的选项: ['老师', '橘子', '飞机', '学校']
    (本轮正确答案是索引 2: '飞机')
    计算出的相似度:
        - 选项 '老师': 0.7896
        - 选项 '橘子': 0.8876
        - 选项 '飞机': 0.8431
        - 选项 '学校': 0.8704
    Listener的选择: 索引 1 -> '橘子'
    ❌ 结论: 猜测错误！

▶️  阶段 4: 复合损失计算 (详细分解)
    [A] Listener Loss:
        - 基础交叉熵损失: 1.3916
        - 奖惩系数: 1.10 (惩罚)
        -  => 最终 Listener Loss = 1.5307
    [B] Alignment Loss (吸引力):
        - 目标: 拉近'an object of motion,...'和'飞机'的语义距离
        -  => 计算出的 Alignment Loss = -0.0281
    [C] Anti-Alignment Loss (排斥力):
        - 目标: 推远'an object of motion,...'和被错选的'橘子'的语义距离
        -  => 计算出的 Anti-Alignment Loss = 0.0224
    [D] Contrastive Loss (区分力):
        - 目标: 让'an object of motion,...'与'飞机'的相似度远高于其他所有选项
        -  => 计算出的 Contrastive Loss = 1.2061
    [E] 总损失计算:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5307 + (0.5 * -0.0281) + (0.5 * 0.0224) + (0.5 * 1.2061)
                   = 1.5307 + -0.0140 + 0.0112 + 0.6031
        ----------------------------------------
        ==> 💸 最终总损失 (Final Total Loss): 2.1310

▶️  阶段 5: 模型协同更新
    执行 total_loss.backward() 计算两个Agent所有相关参数的梯度...
    执行 speaker.optimizer.step() 更新 GPT-2 的权重...
    执行 listener.optimizer.step() 更新 CPM 的权重...
    ✅ 更新完成!


========================= 游戏回合 2 =========================

▶️  阶段 1: 角色分配与任务设置
    🗣️  Speaker: CPM
    👂  Listener: GPT-2

▶️  阶段 2: Speaker 生成描述
    Speaker接收到的概念: '飞机'
    Speaker生成的描述: '3. While 'concept' is description of the'

▶️  阶段 3: Listener 理解与猜测
    Listener接收到的选项: ['airplane', 'orange', 'school', 'teacher']
    (本轮正确答案是索引 0: 'airplane')
    计算出的相似度:
        - 选项 'airplane': 0.5060
        - 选项 'orange': 0.5799
        - 选项 'school': 0.4480
        - 选项 'teacher': 0.5350
    Listener的选择: 索引 1 -> 'orange'
    ❌ 结论: 猜测错误！

▶️  阶段 4: 复合损失计算 (详细分解)
    [A] Listener Loss:
        - 基础交叉熵损失: 1.3987
        - 奖惩系数: 1.10 (惩罚)
        -  => 最终 Listener Loss = 1.5385
    [B] Alignment Loss (吸引力):
        - 目标: 拉近'3. While 'concept' i...'和'airplane'的语义距离
        -  => 计算出的 Alignment Loss = -0.0391
    [C] Anti-Alignment Loss (排斥力):
        - 目标: 推远'3. While 'concept' i...'和被错选的'orange'的语义距离
        -  => 计算出的 Anti-Alignment Loss = 0.0316
    [D] Contrastive Loss (区分力):
        - 目标: 让'3. While 'concept' i...'与'airplane'的相似度远高于其他所有选项
        -  => 计算出的 Contrastive Loss = 1.2820
    [E] 总损失计算:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5385 + (0.5 * -0.0391) + (0.5 * 0.0316) + (0.5 * 1.2820)
                   = 1.5385 + -0.0195 + 0.0158 + 0.6410
        ----------------------------------------
        ==> 💸 最终总损失 (Final Total Loss): 2.1758

▶️  阶段 5: 模型协同更新
    执行 total_loss.backward() 计算两个Agent所有相关参数的梯度...
    执行 speaker.optimizer.step() 更新 CPM 的权重...
    执行 listener.optimizer.step() 更新 GPT-2 的权重...
    ✅ 更新完成!


========================= 游戏回合 3 =========================

▶️  阶段 1: 角色分配与任务设置
    🗣️  Speaker: GPT-2
    👂  Listener: CPM

▶️  阶段 2: Speaker 生成描述
    Speaker接收到的概念: 'cat'
    Speaker生成的描述: 'a long-legged, large, intelligent, playful, and intelligent little black cat known for its playful antics and its intelligence.'

▶️  阶段 3: Listener 理解与猜测
    Listener接收到的选项: ['狗', '猫', '书本', '沙发']
    (本轮正确答案是索引 1: '猫')
    计算出的相似度:
        - 选项 '狗': 0.8668
        - 选项 '猫': 0.8714
        - 选项 '书本': 0.8622
        - 选项 '沙发': 0.8506
    Listener的选择: 索引 1 -> '猫'
    ✅ 结论: 猜测正确！

▶️  阶段 4: 复合损失计算 (详细分解)
    [A] Listener Loss:
        - 基础交叉熵损失: 1.3777
        - 奖惩系数: 0.90 (奖励)
        -  => 最终 Listener Loss = 1.2399
    [B] Alignment Loss (吸引力):
        - 目标: 拉近'a long-legged, large...'和'猫'的语义距离
        -  => 计算出的 Alignment Loss = -0.0071
    [C] Anti-Alignment Loss (排斥力):
        - (猜测正确，无需计算此项损失)
    [D] Contrastive Loss (区分力):
        - 目标: 让'a long-legged, large...'与'猫'的相似度远高于其他所有选项
        -  => 计算出的 Contrastive Loss = 1.3728
    [E] 总损失计算:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.2399 + (0.5 * -0.0071) + (0.5 * 0.0000) + (0.5 * 1.3728)
                   = 1.2399 + -0.0036 + 0.0000 + 0.6864
        ----------------------------------------
        ==> 💸 最终总损失 (Final Total Loss): 1.9227

▶️  阶段 5: 模型协同更新
    执行 total_loss.backward() 计算两个Agent所有相关参数的梯度...
    执行 speaker.optimizer.step() 更新 GPT-2 的权重...
    执行 listener.optimizer.step() 更新 CPM 的权重...
    ✅ 更新完成!


========================= 游戏回合 4 =========================

▶️  阶段 1: 角色分配与任务设置
    🗣️  Speaker: CPM
    👂  Listener: GPT-2

▶️  阶段 2: Speaker 生成描述
    Speaker接收到的概念: '猫'
    Speaker生成的描述: '[1]诗词:泉,泉,泉'

▶️  阶段 3: Listener 理解与猜测
    Listener接收到的选项: ['dog', 'cat', 'sofa', 'book']
    (本轮正确答案是索引 1: 'cat')
    计算出的相似度:
        - 选项 'dog': 0.4614
        - 选项 'cat': 0.4559
        - 选项 'sofa': 0.4563
        - 选项 'book': 0.5672
    Listener的选择: 索引 3 -> 'book'
    ❌ 结论: 猜测错误！

▶️  阶段 4: 复合损失计算 (详细分解)
    [A] Listener Loss:
        - 基础交叉熵损失: 1.4168
        - 奖惩系数: 1.10 (惩罚)
        -  => 最终 Listener Loss = 1.5584
    [B] Alignment Loss (吸引力):
        - 目标: 拉近'[1]诗词:泉,泉,泉...'和'cat'的语义距离
        -  => 计算出的 Alignment Loss = -0.0583
    [C] Anti-Alignment Loss (排斥力):
        - 目标: 推远'[1]诗词:泉,泉,泉...'和被错选的'book'的语义距离
        -  => 计算出的 Anti-Alignment Loss = 0.0606
    [D] Contrastive Loss (区分力):
        - 目标: 让'[1]诗词:泉,泉,泉...'与'cat'的相似度远高于其他所有选项
        -  => 计算出的 Contrastive Loss = 1.3424
    [E] 总损失计算:
        ----------------------------------------
        Total Loss = Listener_Loss + (W_align * Align_L) + (W_anti * Anti_L) + (W_contrast * Contrast_L)
                   = 1.5584 + (0.5 * -0.0583) + (0.5 * 0.0606) + (0.5 * 1.3424)
                   = 1.5584 + -0.0292 + 0.0303 + 0.6712
        ----------------------------------------
        ==> 💸 最终总损失 (Final Total Loss): 2.2308

▶️  阶段 5: 模型协同更新
    执行 total_loss.backward() 计算两个Agent所有相关参数的梯度...
    执行 speaker.optimizer.step() 更新 CPM 的权重...
    执行 listener.optimizer.step() 更新 GPT-2 的权重...
    ✅ 更新完成!


========================= 训练结束 =========================
✅ 准确率: 25.00% | 平均损失: 2.1151
📄 详细结果已保存至: /ubsnhome/23063003r/refgame_project/output/final_training_run_results_verbose.json
✅ 作业结束于: Wed Jun 25 06:11:31 UTC 2025
